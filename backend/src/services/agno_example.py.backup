"""
Exemple d'implémentation avec Agno comme alternative au service OpenAI actuel.
Nécessite l'installation de dépendances supplémentaires:
    pip install agno duckduckgo-search lancedb
"""

import os
from dotenv import load_dotenv
import json
import logging
from agno.agent import Agent
from agno.models.openai import OpenAIChat
from agno.tools.duckduckgo import DuckDuckGoTools

load_dotenv()
logger = logging.getLogger(__name__)

class AgnoService:
    def __init__(self):
        self.model_id = "gpt-4-turbo"  # ou gpt-4o
        self.load_system_prompt()
        
    def load_system_prompt(self):
        """Charge le prompt système depuis un fichier JSON"""
        try:
            prompt_path = os.path.join(os.path.dirname(os.path.dirname(__file__)), 'prompts', 'system_prompt.json')
            if os.path.exists(prompt_path):
                with open(prompt_path, 'r', encoding='utf-8') as f:
                    prompt_data = json.load(f)
                    self.system_prompt = prompt_data.get('system_prompt', '')
                    self.response_instructions = prompt_data.get('response_instructions', '')
            else:
                self.system_prompt = "Tu es un assistant virtuel représentant Lucas Bometon."
                self.response_instructions = "Fournir des réponses courtes et concises."
                logger.warning(f"Prompt file not found at {prompt_path}, using default")
        except Exception as e:
            logger.error(f"Error loading system prompt: {str(e)}")
            self.system_prompt = "Tu es un assistant virtuel représentant Lucas Bometon."
            self.response_instructions = "Fournir des réponses courtes et concises."

    def create_agent(self, with_web_search=False):
        """Crée un agent Agno avec ou sans recherche web"""
        description = self.system_prompt
        instructions = [self.response_instructions]
        
        # Liste d'outils
        tools = []
        if with_web_search:
            tools.append(DuckDuckGoTools())
        
        return Agent(
            model=OpenAIChat(id=self.model_id),
            description=description,
            instructions=instructions,
            tools=tools,
            show_tool_calls=True  # Affiche les appels d'outils pour le debug
        )

    async def generate_response(self, query: str, context: str = "") -> str:
        """Génère une réponse en utilisant l'agent Agno"""
        try:
            # Créer l'agent (avec recherche web pour les questions nécessitant des infos externes)
            agent = self.create_agent(with_web_search=True)
            
            # Préparer la question avec le contexte si disponible
            final_query = query
            if context:
                final_query = f"Contexte: {context}\n\nQuestion: {query}"
            
            # Obtenir la réponse de l'agent (la méthode run() n'est pas async)
            response = agent.run(final_query)
            
            # Extraire et retourner la réponse (l'attribut est 'content', pas 'message')
            return response.content
            
        except Exception as e:
            logger.error(f"Error generating Agno response: {str(e)}")
            raise

# Exemple d'utilisation:
async def test_agno():
    service = AgnoService()
    try:
        # Nous gardons async/await pour la compatibilité avec le reste de l'API
        response = await service.generate_response(
            "Comment intégrer l'IA dans un processus de design thinking?"
        )
        print(response)
    except Exception as e:
        print(f"Erreur lors du test: {str(e)}")

if __name__ == "__main__":
    import asyncio
    asyncio.run(test_agno()) 